Big O Notation is a way to scale how well a computer algorithm scales as the amount of data involved increases.Big O is used to describe the efficiency of algorithms.
Time Complexity Examples
No matter how big the constant is and how slow the linear increase is, linear will at some point surpass
constant.